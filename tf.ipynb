{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martianmartina/FaceEditor/blob/master/tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "id": "vOuUZqhpObMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbba3218-0b17-4a7b-ec3d-b6b490d771a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
        "FOLDERNAME = 'FaceEditor'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
      ],
      "metadata": {
        "id": "vpDLjVGjMS0z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My\\ Drive/$FOLDERNAME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vd0QtfSMa9R",
        "outputId": "4e1f4a12-3b61-48bb-bc9c-7f1b1ce8b3ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/FaceEditor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, gc, zipfile\n",
        "import random\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "PATH = './photos/'\n",
        "IMAGES = os.listdir(PATH)\n",
        "print('There are',len(IMAGES),'images. Here are 5 example filesnames:')\n",
        "print(IMAGES[:5])"
      ],
      "metadata": {
        "id": "uRFDbb6GF9V-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00518d5a-7a9f-45f8-c162-caeff13a00be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 188 images. Here are 5 example filesnames:\n",
            "['m-039-01.jpg', 'm-027-01.jpg', 'm-078-01.jpg', 'm-072-01.jpg', 'm-018-01.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not used now\n",
        "def showarray(a, fmt='jpeg'):\n",
        "    ''' Helper function. Use this to show your filters\n",
        "    \n",
        "    Converting to standard image format is a common task that produces garbage\n",
        "    images when not done correctly. We've provided the correct conversions'''\n",
        "    a = np.uint8(np.clip(a, 0, 255))\n",
        "    f = BytesIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    display(Image(data=f.getvalue()))"
      ],
      "metadata": {
        "id": "f5IQKV6kbJLN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def brightness(img, low, high):\n",
        "    value = random.uniform(low, high)\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    hsv = np.array(hsv, dtype = np.float64)\n",
        "    hsv[:,:,1] = hsv[:,:,1]*value\n",
        "    hsv[:,:,1][hsv[:,:,1]>255]  = 255\n",
        "    hsv[:,:,2] = hsv[:,:,2]*value \n",
        "    hsv[:,:,2][hsv[:,:,2]>255]  = 255\n",
        "    hsv = np.array(hsv, dtype = np.uint8)\n",
        "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    return img"
      ],
      "metadata": {
        "id": "ycZbrtt6GUbk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs_array=[]\n",
        "for i in range(len(IMAGES)):\n",
        "  image = cv2.imread(PATH + IMAGES[i%len(IMAGES)])\n",
        "  # as opencv load image in bgr format converting it to rgb\n",
        "  #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  \n",
        "  image = cv2.resize(image,( 128, int(image.shape[0]/(image.shape[1]/128)) ))\n",
        "  # cropping + better to choose convtranspose parameter\n",
        "  image = image[12:140,:]       # (128,128,3)\n",
        "  imgs_array.append(img_to_array(image))\n",
        "  \n",
        "  # data augmentation: \n",
        "  # horizontal flip\n",
        "  image_1 = cv2.flip(image,1)\n",
        "  imgs_array.append(img_to_array(image))\n",
        "  # brightness\n",
        "  image_2 = brightness(image,0.6,1.3)\n",
        "  imgs_array.append(img_to_array(image_2))\n",
        "  # horizontal flip + brightness\n",
        "  image_3 = brightness(image_1,0.6,1.3)\n",
        "  imgs_array.append(img_to_array(image_3))\n",
        "\n",
        "import random\n",
        "random.shuffle(imgs_array)"
      ],
      "metadata": {
        "id": "hbfT-I5faerj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs_array = np.asarray(imgs_array,dtype=np.float32)\n",
        "print(imgs_array.shape)\n",
        "\n",
        "#Spliting the data\n",
        "imgs_train_y = imgs_array[:700]/255.0\n",
        "imgs_test = imgs_array[700:]/255.0\n",
        "imgs_train_x = np.expand_dims(np.arange(imgs_train_y.shape[0]), axis=1)\n",
        "print(imgs_train_y.shape)\n",
        "print(imgs_train_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szSrxkOfjh7L",
        "outputId": "932d6cb1-2b09-4a53-96f8-71f769d14605"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(752, 128, 128, 3)\n",
            "(700, 128, 128, 3)\n",
            "(700, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGzqY2GalK60",
        "outputId": "653e5300-7d38-43c9-f911-f1014aa0f7a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from dutil import *\n",
        "import pydot\n",
        "\n",
        "SHIFT_AMOUNT = 9\n",
        "BATCH_SIZE = 8\n",
        "NUM_KERNELS = 20\n",
        "CONTINUE_TRAIN = False\n",
        "SIZE = 128 # 128*128 image\n",
        "\n",
        "NUM_EPOCHS = 2000\n",
        "PARAM_SIZE = 80\n",
        "LR = 0.001\n",
        "NUM_RAND_FACES = BATCH_SIZE\n",
        "NUM_TEST_FACES = BATCH_SIZE\n",
        "\n",
        "def plotScores(scores, test_scores, fname, on_top=True):\n",
        "\tplt.clf()\n",
        "\tax = plt.gca()\n",
        "\tax.yaxis.tick_right()\n",
        "\tax.yaxis.set_ticks_position('both')\n",
        "\tax.yaxis.grid(True)\n",
        "\tplt.plot(scores)\n",
        "\tplt.plot(test_scores)\n",
        "\tplt.xlabel('Epoch')\n",
        "\tplt.ylim([0.0, 0.01])\n",
        "\tloc = ('upper right' if on_top else 'lower right')\n",
        "\tplt.legend(['Train', 'Test'], loc=loc)\n",
        "\tplt.draw()\n",
        "\tplt.savefig(fname)\n"
      ],
      "metadata": {
        "id": "OS45byu6wBdC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Jg4N-InARMVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971faf55-6955-4970-9de3-fc79c624b9a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Keras...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR (theano.gpuarray): pygpu was configured but could not be imported or is too old (version 0.7 or higher required)\n",
            "NoneType: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theano Version: 1.1.2\n",
            "Building Model...\n",
            "(None, 80)\n",
            "(None, 1, 1, 80)\n",
            "(None, 2, 2, 128)\n",
            "(None, 6, 6, 64)\n",
            "(None, 14, 14, 32)\n",
            "(None, 30, 30, 16)\n",
            "(None, 62, 62, 8)\n",
            "(None, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "###################################\n",
        "#  Create Model\n",
        "###################################\n",
        "print (\"Loading Keras...\")\n",
        "import os, math\n",
        "os.environ['THEANORC'] = \"./gpu.theanorc\"\n",
        "os.environ['KERAS_BACKEND'] = \"theano\"\n",
        "import theano\n",
        "print( \"Theano Version: \" + theano.__version__)\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, Flatten, Reshape, SpatialDropout2D\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras import Model, Sequential\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "num_samples = imgs_train_y.shape[0]\n",
        "\n",
        "if CONTINUE_TRAIN:\n",
        "\tprint(\"Loading Model...\")\n",
        "\tmodel = load_model('Encoder.h5')\n",
        "else:\n",
        "\tprint (\"Building Model...\")\n",
        " \n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Input(shape=(1)))\n",
        "\t\n",
        "\tmodel.add(Embedding(num_samples, PARAM_SIZE, input_length=1))\n",
        "\tmodel.add(Flatten(name='pre_encoder'))\n",
        "\tprint(model.output_shape)            #(None, 80)\n",
        "\tassert(model.output_shape == (None, PARAM_SIZE))\n",
        "\t\n",
        "\tmodel.add(Reshape((1,1,PARAM_SIZE), name='encoder'))\n",
        "\tprint( model.output_shape)\n",
        "\t\n",
        "\tmodel.add(Conv2DTranspose(128, 2))           \n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\tprint(model.output_shape)\n",
        "\n",
        "\tmodel.add(Conv2DTranspose(64, 4, strides=2))    #(6, 6)              \n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\tprint(model.output_shape)\n",
        "\t\n",
        "\tmodel.add(Conv2DTranspose(32, 4, strides=2))    #(14, 14)            \n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\tprint(model.output_shape)\n",
        "\t\n",
        "\tmodel.add(Conv2DTranspose(16, 4, strides=2))    #(30, 30)  \n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\tprint(model.output_shape)\n",
        "\t\n",
        "\tmodel.add(Conv2DTranspose(8, 4, strides=2))    #(62, 62)\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\tprint(model.output_shape)\n",
        "\t\n",
        "\n",
        "\tmodel.add(Conv2DTranspose(3, 6, strides=2))     #(128, 128)\n",
        "\tmodel.add(Activation(\"sigmoid\",name='output')) \n",
        "\tprint(model.output_shape)\n",
        "\tassert(model.output_shape[1:] == (128,128,3))\n",
        "\n",
        "\tmodel.compile(optimizer=Adam(learning_rate=LR), loss='mse')\n",
        "\tplot_model(model, to_file='model.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################################\n",
        "#  Encoder / Decoder\n",
        "###################################\n",
        "print( \"Compiling SubModels...\")\n",
        "#print(model.layers[1].output)\n",
        "#print(model.layers[-1])\n",
        "func = Model(inputs=model.get_layer('encoder').input,\n",
        "\t\t\t\t  outputs=model.layers[-1].output)\n",
        "enc_model = Model(inputs=model.input,\n",
        "                  outputs=model.get_layer('pre_encoder').output)\n",
        "\n",
        "rand_vecs = np.random.normal(0.0, 1.0, (NUM_RAND_FACES, PARAM_SIZE))\n",
        "\n",
        "def save_image(x, fname):\n",
        "    img = x*255\n",
        "    #img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    cv2.imwrite(fname, img)\n",
        "def make_rand_faces(rand_vecs, iters):\n",
        "    x_enc = enc_model.predict(imgs_train_x, batch_size=BATCH_SIZE)\n",
        "\t\n",
        "    x_mean = np.mean(x_enc, axis=0)\n",
        "    x_stds = np.std(x_enc, axis=0)\n",
        "    x_cov = np.cov((x_enc - x_mean).T)\n",
        "    e, v = np.linalg.eig(x_cov)\n",
        " \n",
        "    np.save('means.npy', x_mean)\n",
        "    np.save('stds.npy', x_stds)\n",
        "    np.save('evals.npy', e)\n",
        "    np.save('evecs.npy', v)\n",
        " \n",
        "    e_list = e.tolist()\n",
        "    e_list.sort(reverse=True)\n",
        "    plt.clf()\n",
        "    plt.bar(np.arange(e.shape[0]), e_list, align='center')\n",
        "    plt.draw()\n",
        "    plt.title('top 80 eigen values')\n",
        "    plt.savefig('evals.png')\n",
        "    x_vecs = x_mean + np.dot(v, (rand_vecs * e).T).T\n",
        "    y_faces = func.predict(x_vecs)\n",
        "    for i in range(y_faces.shape[0]):\n",
        "        #channels_first = np.transpose(y_faces[i],(2,0,1)) # (3, 128, 128)\n",
        "        save_image(y_faces[i], 'rand' + str(i) + '.png')\n",
        "        if i < 5 and (iters % 10) == 0:\n",
        "            if not os.path.exists('morph' + str(i)):\n",
        "                os.makedirs('morph' + str(i))\n",
        "            save_image(y_faces[i], 'morph' + str(i) + '/img' + str(iters) + '.png')\n",
        "\n",
        "make_rand_faces(rand_vecs, 0)\n",
        "\t\t\t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "OFy54boKwIGO",
        "outputId": "037c852b-ccf7-4e72-b184-2293cdc4f80d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling SubModels...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################################\n",
        "#  Train\n",
        "###################################\n",
        "print( \"Training...\")\n",
        "train_loss = []\n",
        "\n",
        "for iters in range(NUM_EPOCHS):\n",
        "    history = model.fit(imgs_train_x, imgs_train_y, batch_size=BATCH_SIZE, epochs=1)\n",
        "\n",
        "    loss = history.history['loss'][-1]\n",
        "    train_loss.append(loss)\n",
        "    print(\"Loss: \" + str(loss))\n",
        "    plotScores(train_loss, [], 'EncoderScores.png', True)\n",
        "\t\n",
        "    if iters % 20 == 0:\n",
        "        model.save('Encoder.h5')\n",
        "        y_faces = model.predict(imgs_train_x[:NUM_TEST_FACES], batch_size=BATCH_SIZE)\n",
        "        for i in range(y_faces.shape[0]):\n",
        "            #channels_first = np.transpose(y_faces[i],(2,0,1))\n",
        "            save_image(y_faces[i], 'gt' + str(i) + '.png')\n",
        "        make_rand_faces(rand_vecs, iters)\n",
        "        print(\"Saved\")\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0ZhO-UzwJPj",
        "outputId": "e0e76296-bd7d-4ea9-e91d-70e50b74d906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n",
            "88/88 [==============================] - 6s 67ms/step - loss: 0.0098\n",
            "Loss: 0.009787318296730518\n",
            "Saved\n",
            "88/88 [==============================] - 5s 58ms/step - loss: 0.0095\n",
            "Loss: 0.00948250200599432\n",
            "88/88 [==============================] - 5s 59ms/step - loss: 0.0091\n",
            "Loss: 0.009106850251555443\n",
            "88/88 [==============================] - 5s 57ms/step - loss: 0.0088\n",
            "Loss: 0.008817631751298904\n",
            "88/88 [==============================] - 5s 58ms/step - loss: 0.0086\n",
            "Loss: 0.008609160780906677\n",
            "88/88 [==============================] - 5s 57ms/step - loss: 0.0083\n",
            "Loss: 0.00829312764108181\n",
            "88/88 [==============================] - 5s 58ms/step - loss: 0.0080\n",
            "Loss: 0.007967221550643444\n",
            "88/88 [==============================] - 5s 58ms/step - loss: 0.0077\n",
            "Loss: 0.007704172283411026\n",
            "88/88 [==============================] - 5s 58ms/step - loss: 0.0074\n",
            "Loss: 0.007409438956528902\n",
            "88/88 [==============================] - 5s 57ms/step - loss: 0.0072\n",
            "Loss: 0.007174626924097538\n",
            "88/88 [==============================] - 5s 57ms/step - loss: 0.0070\n",
            "Loss: 0.00698910653591156\n",
            "88/88 [==============================] - 5s 58ms/step - loss: 0.0069\n",
            "Loss: 0.006854413542896509\n",
            "88/88 [==============================] - 5s 57ms/step - loss: 0.0067\n",
            "Loss: 0.006699370685964823\n",
            "88/88 [==============================] - 5s 59ms/step - loss: 0.0065\n",
            "Loss: 0.00652129715308547\n",
            "88/88 [==============================] - 5s 58ms/step - loss: 0.0064\n",
            "Loss: 0.006369695067405701\n",
            "88/88 [==============================] - 5s 57ms/step - loss: 0.0063\n",
            "Loss: 0.0062725539319217205\n",
            "88/88 [==============================] - 5s 59ms/step - loss: 0.0063\n",
            "Loss: 0.006259691435843706\n",
            "88/88 [==============================] - 6s 64ms/step - loss: 0.0062\n",
            "Loss: 0.006241416092962027\n",
            "88/88 [==============================] - 5s 60ms/step - loss: 0.0061\n",
            "Loss: 0.006077360361814499\n",
            "88/88 [==============================] - 5s 60ms/step - loss: 0.0059\n",
            "Loss: 0.005932878237217665\n",
            "88/88 [==============================] - 5s 59ms/step - loss: 0.0058\n",
            "Loss: 0.005822444800287485\n",
            "Saved\n",
            "88/88 [==============================] - 6s 67ms/step - loss: 0.0057\n",
            "Loss: 0.0057280901819467545\n",
            "88/88 [==============================] - 5s 60ms/step - loss: 0.0056\n",
            "Loss: 0.005614908412098885\n",
            "88/88 [==============================] - 5s 59ms/step - loss: 0.0054\n",
            "Loss: 0.005428563337773085\n",
            "88/88 [==============================] - 5s 59ms/step - loss: 0.0052\n",
            "Loss: 0.005246265791356564\n",
            "88/88 [==============================] - 5s 59ms/step - loss: 0.0051\n",
            "Loss: 0.005143171176314354\n",
            "88/88 [==============================] - 5s 60ms/step - loss: 0.0051\n",
            "Loss: 0.005120304878801107\n",
            "88/88 [==============================] - 5s 62ms/step - loss: 0.0051\n",
            "Loss: 0.005098684225231409\n",
            "88/88 [==============================] - 5s 60ms/step - loss: 0.0050\n",
            "Loss: 0.00501473993062973\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.0049\n",
            "Loss: 0.004905518144369125\n",
            "88/88 [==============================] - 5s 60ms/step - loss: 0.0048\n",
            "Loss: 0.004838848486542702\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.0048\n",
            "Loss: 0.004774458706378937\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.0047\n",
            "Loss: 0.0047180550172924995\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.0047\n",
            "Loss: 0.0047115543857216835\n",
            "88/88 [==============================] - 5s 62ms/step - loss: 0.0047\n",
            "Loss: 0.004674889147281647\n",
            "88/88 [==============================] - 5s 62ms/step - loss: 0.0046\n",
            "Loss: 0.004635453224182129\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.0046\n",
            "Loss: 0.004551648627966642\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.0045\n",
            "Loss: 0.004461132455617189\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.0044\n",
            "Loss: 0.004360828548669815\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.0043\n",
            "Loss: 0.004286463372409344\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.0042\n",
            "Loss: 0.004240402020514011\n",
            "Saved\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.0042\n",
            "Loss: 0.0041992575861513615\n",
            "42/88 [=============>................] - ETA: 2s - loss: 0.0041"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(func)\n",
        "print(enc_model)"
      ],
      "metadata": {
        "id": "f11n50Qtv74Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "tf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}